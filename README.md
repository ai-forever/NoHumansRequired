
<p align="center">
  <a href="https://riko0.github.io/No-Humans-Required/">
    <img
      src="https://img.shields.io/badge/NHR-Website-0A66C2?logo=safari&logoColor=white"
      alt="Project Page"
    />
  </a>
  <a href="https://arxiv.org/abs/2507.14119">
    <img
      src="https://img.shields.io/badge/NHR-Paper-red?logo=arxiv&logoColor=red"
      alt="Paper on arXiv"
    />
  </a>
  <a href="https://huggingface.co/datasets/iitolstykh/NHR-Edit">
    <img
      src="https://img.shields.io/badge/NHR_Edit-Data-purple?logo=huggingface&logoColor=yellow"
      alt="NHR-Edit Dataset"
    />
  </a>
  <a href="https://huggingface.co/iitolstykh/Bagel-NHR-Edit">
    <img 
        src="https://img.shields.io/badge/Bagel_NHR_Edit-Model-yellow?logo=huggingface&logoColor=yellow" 
        alt="BAGEL-NHR-Edit Model"
    />
  </a>
  <a href="https://huggingface.co/spaces/iitolstykh/BAGEL-NHR-Edit">
    <img
      src="https://img.shields.io/badge/BAGEL_NHR_Edit-Space-orange?logo=huggingface&logoColor=yellow"
      alt="BAGEL-NHR-Edit Demo"
    />
  </a>
  
</p>

# NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining

> **Maksim Kuprashevich, Grigorii Alekseenko, [Irina Tolstykh](https://www.linkedin.com/in/irina-tolstykh-2a76111a2/), [Georgii Fedorov](https://github.com/georfed),
[Bulat Suleimanov](https://github.com/bsuleymanov), Vladimir Dokholyan, Aleksandr Gordeev**
>
> Recent advances in generative modeling enable image editing assistants that follow natural language instructions without additional user input. Their supervised training requires millions of triplets <original image, instruction, edited image>, yet mining pixel-accurate examples is hard. Each edit must affect only prompt-specified regions, preserve stylistic coherence, respect physical plausibility, and retain visual appeal. The lack of robust automated edit-quality metrics hinders reliable automation at scale. 
We present an automated, modular pipeline that mines high-fidelity triplets across domains, resolutions, instruction complexities, and styles. Built on public generative models and running without human intervention, our system uses a task-tuned Gemini validator to score instruction adherence and aesthetics directly, removing any need for segmentation or grounding models. Inversion and compositional bootstrapping enlarge the mined set by $\approx 2.2\times$, enabling large-scale high-fidelity training data. By automating the most repetitive annotation steps, the approach allows a new scale of training without human labeling effort.
To democratize research in this resource-intensive area, we release **NHR-Edit**, an open dataset of $358k$ high-quality triplets. In the largest cross-dataset evaluation, it **surpasses all public alternatives**. 
We also release **Bagel-NHR-Edit**, an open-source fine-tuned Bagel model, which achieves state-of-the-art metrics in our experiments.

<p align="center"><img src="https://raw.githubusercontent.com/Riko0/No-Humans-Required-Dataset/refs/heads/main/images/pipeline.jpg" width=85%"></p>

**Autonomous Dataset Generation Pipeline.** A fully automated system for creating high-quality image-editing datasets: prompts and edit instructions are generated by an LLM, initial images are produced using Flux, edits are applied via Image2Image models, and Qwen models evaluate instruction adherence and aesthetics, with the best triplets selected by a finetuned Gemini model, ensuring scalable and visually appealing data generation.

## ðŸ“¢ News

[17/07/2025] [NHR-Edit Dataset](https://huggingface.co/datasets/iitolstykh/NHR-Edit) and [Bagel-NHR-Edit](https://huggingface.co/iitolstykh/Bagel-NHR-Edit) has been published on HuggingFace.

[18/07/2025] ðŸ”¥ðŸ”¥ðŸ”¥ Paper has been published on [Arxiv](https://arxiv.org/abs/2507.14119).

[21/07/2025] **Bagel-NHR-Edit Demo** has been published on [HuggingFace ðŸ¤—](https://huggingface.co/spaces/iitolstykh/BAGEL-NHR-Edit).


## NHR-Edit Dataset Info

- Unique source images: 286,608
- Instruction-image pairs (triplets): 358,463
- Image resolution: variable (metadata includes exact width/height)

#### Category group distribution:
<p align="left"><img src="https://raw.githubusercontent.com/Riko0/No-Humans-Required-Dataset/refs/heads/main/images/01_general_categories.jpg" width=42%"> <img src="https://raw.githubusercontent.com/Riko0/No-Humans-Required-Dataset/refs/heads/main/images/02_misc_breakdown.jpg" width=51%"></p>

## Bagel-NHR-Edit Model Info

**Bagel-NHR-Edit** is a model fine-tuned on the NHR-Edit dataset using parameter-efficient LoRA adaptation on the generation expertâ€™s attention and FFN projection layers.

**PWC Leaderboards**: [ImgEdit](https://paperswithcode.com/sota/image-editing-on-imgedit-data?p=nohumansrequired-autonomous-high-quality), [GEdit-Bench-EN](https://paperswithcode.com/sota/image-editing-on-gedit-bench-en?p=nohumansrequired-autonomous-high-quality)

#### Metrics for GEdit-Bench-EN:

| Model         | GEdit-Bench-EN (SC) â†‘ | GEdit-Bench-EN (PQ) â†‘ | GEdit-Bench-EN (O) â†‘|
| ------------- | --------------------- | --------------------- | ------------------- |
| BAGEL-7B-MoT  |          7.983        |        6.570          |       6.921         |
| **BAGEL-NHR-Edit** | 8.067     | 6.881                 | 7.115               |
> *Scoring model:* `gpt-4.1-2025-04-14` *(with default temperature)*

#### Metrics for ImgEdit-Bench:

| Model         | Style | Extract | Remove | Background | Action | Adjust | Add | Replace | Compose | Overall â†‘ |
| ------------- | ----- | ------- | ------ | -----------| ------ | ------ | ----| ------- | ------- | ------- |
| BAGEL-7B-MoT  |      4.22|        1.53|       3.04|      3.3|        4.07|       3.67|      3.98|       3.5 |       3.0 |       3.3 |
| **BAGEL-NHR-Edit** |      4.3|        1.62|       3.18|      3.42|        3.95|      3.55|      4.19|        3.77|       2.94|      3.39|
> *Scoring model:* `gpt-4o-2024-11-20` *(with temperature = 0.0)*

Results comparison between original Bagel-7B-MoT and BAGEL-NHR-EDIT on samples from ImgEdit and GEdit benches:

<p align="center"><img src="https://raw.githubusercontent.com/Riko0/No-Humans-Required-Dataset/refs/heads/main/images/Bagel_NHR_Edit_comp.jpg" width=85%"></p>


## Citation

```bib
@article{Layer2025NoHumansRequired,
    arxivId = {2507.14119},
    author = {Maksim Kuprashevich and Grigorii Alekseenko and Irina Tolstykh and Georgii Fedorov and Bulat Suleimanov and Vladimir Dokholyan and Aleksandr Gordeev},
    title = {{NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining}},
    year = {2025},
    eprint = {2507.14119},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2507.14119},
    journal={arXiv preprint arXiv:2507.14119}
}
```
